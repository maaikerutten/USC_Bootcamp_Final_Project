{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWW1TyjaecRh"
   },
   "source": [
    "# Final Project USC Data Science Bootcamp\n",
    "## LA Crime data analysis and prediction using TensorFlow \n",
    "\n",
    "#### Maaike Rutten,  June 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project I used the crime data found on the City of LA website from 2010 to Present.\n",
    "This dataset reflects incidents of crime in the City of Los Angeles dating back to 2010. \n",
    "This data is transcribed from original crime reports that are typed on paper and therefore there may be \n",
    "some inaccuracies within the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77aETSYDcdoK"
   },
   "source": [
    "This workbook combines a series of technologies and frameworks to read in Los Angeles Crime data and using machine learning predict the probability of crimes in certain age groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded the crime data as a CSV file and loaded it in a Jupyter notebook. \n",
    "\n",
    "The available information in the dataset contains for every individual crime the following: \n",
    "- DR Number   \t\n",
    "- Date Reported   \n",
    "- Date Occurred   \t\n",
    "- Time Occurred   \t\n",
    "- Area ID   \t\n",
    "- Area Name   \t\n",
    "- Reporting District   \t\n",
    "- Crime Code   \t\n",
    "- Crime Code Description   \t\n",
    "- MO Codes   \t\n",
    "- Victim Age   \t\n",
    "- Victim Sex   \t\n",
    "- Victim Descent   \t\n",
    "- Premise Code   \t\n",
    "- Premise Description   \t\n",
    "- Weapon Used Code   \t\n",
    "- Weapon Description   \t\n",
    "- Status Code   \t\n",
    "- Status Description   \t\n",
    "- Crime Code 1   \t\n",
    "- Crime Code 2   \t\n",
    "- Crime Code 3   \t\n",
    "- Crime Code 4   \t\n",
    "- Address   \t\n",
    "- Cross Street   \t\n",
    "- Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQgONe5ecYvE"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQzxON782Eby"
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MPr95UccYvL"
   },
   "source": [
    "## Download wide and deep tensorflow implementation\n",
    "\n",
    "wide and deep model of tensorflow will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTwQzWcn8aBu"
   },
   "outputs": [],
   "source": [
    "! pip install requests\n",
    "! git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRpuysc73Eb-"
   },
   "source": [
    "Add to python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVvFyhnkcYvL"
   },
   "outputs": [],
   "source": [
    "models_path = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "sys.path.append(models_path)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "15Ethw-wcYvP"
   },
   "source": [
    "Connect to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QilS4-0cYvQ"
   },
   "outputs": [],
   "source": [
    "from official.wide_deep import lacrime_dataset\n",
    "from official.wide_deep import lacrime_main\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cD5e3ibAcYvS"
   },
   "source": [
    "Export path to external python process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYOkY8boUptJ"
   },
   "outputs": [],
   "source": [
    "#export PYTHONPATH=${PYTHONPATH}:\"$(pwd)/models\"\n",
    "#running from python you need to set the `os.environ` or the subprocess will not see the directory.\n",
    "\n",
    "if \"PYTHONPATH\" in os.environ:\n",
    "  os.environ['PYTHONPATH'] += os.pathsep +  models_path\n",
    "else:\n",
    "  os.environ['PYTHONPATH'] = models_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrMLazEN6DMj"
   },
   "source": [
    "Run the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "py7MarZl5Yh6"
   },
   "outputs": [],
   "source": [
    "!python -m official.wide_deep.lacrime_main --model_type=wide --train_epochs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AmZ4CpaOcYvV"
   },
   "source": [
    "## Read the LA Crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6y3mj9zKcYva"
   },
   "outputs": [],
   "source": [
    "train_file = \"lacrime.data\"\n",
    "test_file = \"lacrime.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkn1FNmpcYvb"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "train_df = pandas.read_csv(train_file, header = None, names = lacrime_dataset._CSV_COLUMNS)\n",
    "test_df = pandas.read_csv(test_file, header = None, names = lacrime_dataset._CSV_COLUMNS)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZZtXes4cYvf"
   },
   "source": [
    "\n",
    "\n",
    "## Converting Data into Tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mv3as_CEcYvu"
   },
   "outputs": [],
   "source": [
    "ds = lacrime_dataset.input_fn(train_file, num_epochs=5, shuffle=True, batch_size=10)\n",
    "\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "  print('Feature keys:', list(feature_batch.keys())[:5])\n",
    "  print()\n",
    "  print('Age batch   :', feature_batch['Victim_Age'])\n",
    "  print()\n",
    "  print('Label batch :', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "810fnfY5cYvz"
   },
   "source": [
    "Because `Estimators` expect an `input_fn` that takes no arguments, we typically wrap configurable input function into an obejct with the expected signature. For this notebook configure the `train_inpf` to iterate over the data twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnQdpEcVcYv0"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "train_inpf = functools.partial(lacrime_dataset.input_fn, train_file, num_epochs=2, shuffle=True, batch_size=64)\n",
    "test_inpf = functools.partial(lacrime_dataset.input_fn, test_file, num_epochs=1, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKz6LA8_ACI7"
   },
   "source": [
    "#### Numeric columns\n",
    "\n",
    "- Victim age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZX0r2T5OcYv6"
   },
   "outputs": [],
   "source": [
    "age = fc.numeric_column('Victim_Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tnLUiaHxcYv-"
   },
   "source": [
    "The model will use the `feature_column` definitions to build the model input. You can inspect the resulting output using the `input_layer` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kREtIPfwcYv_"
   },
   "outputs": [],
   "source": [
    "fc.input_layer(feature_batch, [age]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPuLduCucYwD"
   },
   "source": [
    "The following will train and evaluate a model using only the `age` feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9R5eSJ1pcYwE"
   },
   "outputs": [],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=[age])\n",
    "classifier.train(train_inpf)\n",
    "result = classifier.evaluate(test_inpf)\n",
    "\n",
    "clear_output()  # used for display in notebook\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDZGcdTdcYwI"
   },
   "source": [
    "Similarly, we can define a `NumericColumn` for each continuous feature column\n",
    "that we want to use in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqPbUqlxcYwJ"
   },
   "outputs": [],
   "source": [
    "timeocurred_num = tf.feature_column.numeric_column('Time_Occurred')\n",
    "\n",
    "my_numeric_columns = [age,timeocurred_num]\n",
    "\n",
    "fc.input_layer(feature_batch, my_numeric_columns).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBGDN97IcYwQ"
   },
   "source": [
    "You could retrain a model on these features by changing the `feature_columns` argument to the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XN8k5S95cYwR"
   },
   "outputs": [],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns)\n",
    "classifier.train(train_inpf)\n",
    "\n",
    "result = classifier.evaluate(test_inpf)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "for key,value in sorted(result.items()):\n",
    "  print('%s: %s' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBRq9_AzcYwU"
   },
   "source": [
    "#### Categorical columns\n",
    "\n",
    "Victim descent is part of a list of possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IjqSi9tcYwV"
   },
   "outputs": [],
   "source": [
    "descent = fc.categorical_column_with_vocabulary_list(\n",
    "    'victim_descent',\n",
    "    ['O', 'B', 'H', 'W', 'X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-RjoWv-7cYwW"
   },
   "source": [
    "Run the  layer,  with both the `age` and `descent` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI43CYlncYwY"
   },
   "outputs": [],
   "source": [
    "fc.input_layer(feature_batch, [age, fc.indicator_column(descent)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTudP7WHcYwb"
   },
   "source": [
    "areaname with `categorical_column_with_hash_bucket` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pSBaliCcYwb"
   },
   "outputs": [],
   "source": [
    "areaname = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'Area_Name', hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSAPrqQkcYwd"
   },
   "source": [
    "each possible value in the  column `area name` is hashed to an integer ID as we encounter them in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCvQNv36cYwe"
   },
   "outputs": [],
   "source": [
    "for item in feature_batch['Area_Name'].numpy():\n",
    "    print(item.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KP5hN2rAcYwh"
   },
   "source": [
    "run the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Y16peWacYwh"
   },
   "outputs": [],
   "source": [
    "areaname_result = fc.input_layer(feature_batch, [fc.indicator_column(areaname)])\n",
    "\n",
    "areaname_result.numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMW2MzWAcYwk"
   },
   "source": [
    "It's easier to see the actual results if we take the `tf.argmax` over the `hash_bucket_size` dimension. N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_ryRglmcYwk"
   },
   "outputs": [],
   "source": [
    "tf.argmax(areaname_result, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdKEqF6xcYwv"
   },
   "source": [
    "### Derived feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgYaf_48FSU2"
   },
   "source": [
    "#### Make Continuous Features Categorical through Bucketization\n",
    "\n",
    "Bucketization of ages to create agegroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KT4pjD9AcYww"
   },
   "outputs": [],
   "source": [
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lr40vm3qcYwy"
   },
   "outputs": [],
   "source": [
    "fc.input_layer(feature_batch, [age, age_buckets]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtjpheB6cYw9"
   },
   "source": [
    "## Define the logistic regression model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Klmf3OxpcYw-"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "base_columns = [\n",
    "     Time_Ocurred, Victim_Sex, descent, areaname_result,\n",
    "    age_buckets,\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=tempfile.mkdtemp(),\n",
    "    feature_columns=base_columns \n",
    "    optimizer=tf.train.FtrlOptimizer(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRhnPxUucYxC"
   },
   "source": [
    "\n",
    "\n",
    "## Train and evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZlrIBuoecYxD"
   },
   "outputs": [],
   "source": [
    "train_inpf = functools.partial(lacrime_dataset.input_fn, train_file,\n",
    "                               num_epochs=40, shuffle=True, batch_size=64)\n",
    "\n",
    "model.train(train_inpf)\n",
    "\n",
    "clear_output()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvY3a9pzcYxH"
   },
   "source": [
    "evaluate the accuracy of the model by predicting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9nVJEO8cYxI"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_inpf)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "for key,value in sorted(results.items()):\n",
    "  print('%s: %0.2f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0fAibNDcYxL"
   },
   "source": [
    "evaluate how the model performed against real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8R5bz5CxcYxL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predict_df = test_df[:20].copy()\n",
    "\n",
    "pred_iter = model.predict(\n",
    "    lambda:easy_input_function(predict_df, label_key='Victim_Sex',\n",
    "                               num_epochs=1, shuffle=False, batch_size=10))\n",
    "\n",
    "classes = np.array(['M', 'F'])\n",
    "pred_class_id = []\n",
    "\n",
    "for pred_dict in pred_iter:\n",
    "  pred_class_id.append(pred_dict['class_ids'])\n",
    "\n",
    "predict_df['predicted_class'] = classes[np.array(pred_class_id)]\n",
    "predict_df['correct'] = predict_df['predicted_class'] == predict_df['Victim_Sex']\n",
    "\n",
    "clear_output()\n",
    "\n",
    "predict_df[['Victim_Sex','predicted_class', 'correct']]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MWW1TyjaecRh"
   ],
   "name": "linear.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
